{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a13a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe25b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b46baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fc1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data file\n",
    "input_file = '../datasets/mawi_packet_trace_original.csv'\n",
    "packet_trace = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6320e45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "1688187656    131519\n",
       "1688187664    124474\n",
       "1688187665    122160\n",
       "1688187680    120930\n",
       "1688187604    118928\n",
       "               ...  \n",
       "1688187651     89117\n",
       "1688187623     89055\n",
       "1688187650     86556\n",
       "1688187600     85774\n",
       "1688187692     79855\n",
       "Name: count, Length: 93, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet_trace['timestamp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c1e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>protocol</th>\n",
       "      <th>pkt_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.441776e+06</td>\n",
       "      <td>9.441776e+06</td>\n",
       "      <td>9.441776e+06</td>\n",
       "      <td>9.441776e+06</td>\n",
       "      <td>9.441776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>1.793662e+04</td>\n",
       "      <td>2.512101e+04</td>\n",
       "      <td>8.800011e+00</td>\n",
       "      <td>5.585487e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.701577e+01</td>\n",
       "      <td>2.300241e+04</td>\n",
       "      <td>2.475920e+04</td>\n",
       "      <td>8.236224e+00</td>\n",
       "      <td>9.559149e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>2.660000e+02</td>\n",
       "      <td>4.430000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>5.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>3.478000e+03</td>\n",
       "      <td>1.320600e+04</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>4.163100e+04</td>\n",
       "      <td>5.252900e+04</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.051000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.688188e+09</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>2.049400e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp      src_port      dst_port      protocol      pkt_size\n",
       "count  9.441776e+06  9.441776e+06  9.441776e+06  9.441776e+06  9.441776e+06\n",
       "mean   1.688188e+09  1.793662e+04  2.512101e+04  8.800011e+00  5.585487e+02\n",
       "std    2.701577e+01  2.300241e+04  2.475920e+04  8.236224e+00  9.559149e+02\n",
       "min    1.688188e+09  0.000000e+00  0.000000e+00  1.000000e+00  5.400000e+01\n",
       "25%    1.688188e+09  2.660000e+02  4.430000e+02  6.000000e+00  5.800000e+01\n",
       "50%    1.688188e+09  3.478000e+03  1.320600e+04  6.000000e+00  6.600000e+01\n",
       "75%    1.688188e+09  4.163100e+04  5.252900e+04  6.000000e+00  1.051000e+03\n",
       "max    1.688188e+09  6.553500e+04  6.553500e+04  1.320000e+02  2.049400e+04"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet_trace.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de98e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9441776 entries, 0 to 9441775\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   timestamp  int64 \n",
      " 1   src_ip     object\n",
      " 2   dst_ip     object\n",
      " 3   src_port   int64 \n",
      " 4   dst_port   int64 \n",
      " 5   protocol   int64 \n",
      " 6   pkt_size   int64 \n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 504.2+ MB\n"
     ]
    }
   ],
   "source": [
    "packet_trace.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81e4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(start_time, end_time):\n",
    "    timestamp1 = datetime.fromtimestamp(start_time)\n",
    "    timestamp2 = datetime.fromtimestamp(end_time)\n",
    "\n",
    "    # Calculate the duration\n",
    "    duration = timestamp2 - timestamp1\n",
    "\n",
    "    if duration.seconds >= 60:\n",
    "        duration = f'{int(duration.seconds / 60)} mins'\n",
    "    else:\n",
    "        duration = f'{int(duration.seconds)} seconds'\n",
    "    \n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07881c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Period: 1 mins\n",
      "Unique Source IPs: 122332, Unique Destination IPs: 351872\n",
      "Unique Source Ports: 65479, Unique Destination Ports: 64919\n",
      "Unique Protocols: 9\n"
     ]
    }
   ],
   "source": [
    "period = get_duration(packet_trace['timestamp'].iloc[0], packet_trace['timestamp'].iloc[-1])\n",
    "\n",
    "unique_src_ips = len(packet_trace['src_ip'].unique())\n",
    "unique_dst_ips = len(packet_trace['dst_ip'].unique())\n",
    "\n",
    "unique_src_ports = len(packet_trace['src_port'].unique())\n",
    "unique_dst_ports = len(packet_trace['dst_port'].unique())\n",
    "\n",
    "unique_protocols = len(packet_trace['protocol'].unique())\n",
    "\n",
    "print(f'Total Time Period: {period}')\n",
    "print(f'Unique Source IPs: {unique_src_ips}, Unique Destination IPs: {unique_dst_ips}')\n",
    "print(f'Unique Source Ports: {unique_src_ports}, Unique Destination Ports: {unique_dst_ports}')\n",
    "print(f'Unique Protocols: {unique_protocols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a6c0d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "src_ip       0\n",
       "dst_ip       0\n",
       "src_port     0\n",
       "dst_port     0\n",
       "protocol     0\n",
       "pkt_size     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packet_trace.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7750ddd-b5fd-44e0-aee4-e47efe82cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flows(data, pkt_size_col = 1, elephant_flow_threshold = 100000):\n",
    "    # Create a dictionary to store flow information\n",
    "    flows = {}\n",
    "\n",
    "    pkt_size_columns = {}\n",
    "    for i in range(2, pkt_size_col+1):\n",
    "        pkt_size_columns[f'pkt_size_{i}'] = 0\n",
    "    \n",
    "    # Iterate through the dataset\n",
    "    for index, row in data.iterrows():\n",
    "        # Extract relevant packet attributes \n",
    "        timestamp = row['timestamp']\n",
    "        src_ip = row['src_ip']\n",
    "        dst_ip = row['dst_ip']\n",
    "        src_port = row['src_port']\n",
    "        dst_port = row['dst_port']\n",
    "        protocol = row['protocol']\n",
    "        pkt_size = row['pkt_size']\n",
    "\n",
    "        if protocol == 6 or protocol == 17:\n",
    "            # Create a unique key for the flow based on the packet attributes\n",
    "            flow_key = (src_ip, dst_ip, src_port, dst_port, protocol)\n",
    "    \n",
    "            # Check if the flow already exists in the dictionary\n",
    "            if flow_key in flows:\n",
    "                pkt_count = flows[flow_key]['flow_pkt_count'] + 1\n",
    "    \n",
    "                # multi pkt features\n",
    "                if pkt_size_col > 1 and pkt_count <= pkt_size_col:\n",
    "                    # update packet size columns\n",
    "                    flows[flow_key][f'pkt_size_{pkt_count}'] = pkt_size\n",
    "    \n",
    "                    # Total size\n",
    "                    flows[flow_key][f'{pkt_size_col}_pkt_size'] += pkt_size\n",
    "    \n",
    "                    # maximum inter arrival time\n",
    "                    if flows[flow_key][f'{pkt_size_col}_pkt_max_iat'] < row['timestamp'] - flows[flow_key]['end_time']:\n",
    "                        flows[flow_key][f'{pkt_size_col}_pkt_max_iat'] = row['timestamp'] - flows[flow_key]['end_time']\n",
    "    \n",
    "                    # mean inter arrival time\n",
    "                    if flows[flow_key]['flow_mean_iat'] > 0:\n",
    "                        flows[flow_key][f'{pkt_size_col}_pkt_mean_iat'] = np.mean([flows[flow_key]['flow_mean_iat'], (row['timestamp'] - flows[flow_key]['end_time'])])\n",
    "                    else:\n",
    "                        flows[flow_key][f'{pkt_size_col}_pkt_mean_iat'] = row['timestamp'] - flows[flow_key]['end_time']\n",
    "                        \n",
    "                    # duration\n",
    "                    flows[flow_key][f'{pkt_size_col}_pkt_duration'] = row['timestamp'] - flows[flow_key]['start_time']\n",
    "                    \n",
    "                # flow features\n",
    "                flows[flow_key]['flow_size'] += pkt_size\n",
    "                flows[flow_key]['flow_pkt_count'] += 1\n",
    "    \n",
    "                # maximum inter arrival time\n",
    "                if flows[flow_key]['flow_max_iat'] < row['timestamp'] - flows[flow_key]['end_time']:\n",
    "                    flows[flow_key]['flow_max_iat'] = row['timestamp'] - flows[flow_key]['end_time']\n",
    "    \n",
    "                # mean inter arrival time\n",
    "                if flows[flow_key]['flow_mean_iat'] > 0:\n",
    "                    flows[flow_key]['flow_mean_iat'] = np.mean([flows[flow_key]['flow_mean_iat'], (row['timestamp'] - flows[flow_key]['end_time'])])                \n",
    "                else:\n",
    "                    flows[flow_key]['flow_mean_iat'] = row['timestamp'] - flows[flow_key]['end_time']\n",
    "                    \n",
    "                # flow duration\n",
    "                flows[flow_key]['flow_duration'] = row['timestamp'] - flows[flow_key]['start_time']\n",
    "    \n",
    "                # update elephant or mice\n",
    "                if flows[flow_key]['flow_size'] > elephant_flow_threshold:\n",
    "                    flows[flow_key]['elephant'] = 1\n",
    "    \n",
    "                flows[flow_key]['end_time'] = row['timestamp']\n",
    "                \n",
    "            else:\n",
    "                # Create a new entry for the flow\n",
    "                if pkt_size_col > 1:\n",
    "                    flows[flow_key] = {\n",
    "                        'start_time': timestamp,\n",
    "                        'end_time': timestamp,\n",
    "                        'src_ip': src_ip,\n",
    "                        'dst_ip': dst_ip,\n",
    "                        'protocol': protocol,\n",
    "                        'src_port': src_port,\n",
    "                        'dst_port': dst_port,\n",
    "                        'pkt_size_1': pkt_size,\n",
    "                        **pkt_size_columns,\n",
    "                        f'{pkt_size_col}_pkt_size': pkt_size,\n",
    "                        f'{pkt_size_col}_pkt_max_iat': 0,\n",
    "                        f'{pkt_size_col}_pkt_mean_iat': 0,\n",
    "                        f'{pkt_size_col}_pkt_duration': 0,\n",
    "                        'flow_size': pkt_size,\n",
    "                        'flow_pkt_count': 1,\n",
    "                        'flow_max_iat': 0,\n",
    "                        'flow_mean_iat': 0,\n",
    "                        'flow_duration': 0,\n",
    "                        'elephant': 0,\n",
    "                    }\n",
    "    \n",
    "                else:\n",
    "                    flows[flow_key] = {\n",
    "                        'start_time': timestamp,\n",
    "                        'end_time': timestamp,\n",
    "                        'src_ip': src_ip,\n",
    "                        'dst_ip': dst_ip,\n",
    "                        'protocol': protocol,\n",
    "                        'src_port': src_port,\n",
    "                        'dst_port': dst_port,\n",
    "                        'pkt_size_1': pkt_size,\n",
    "                        'flow_size': pkt_size,\n",
    "                        'flow_pkt_count': 1,\n",
    "                        'flow_max_iat': 0,\n",
    "                        'flow_mean_iat': 0,\n",
    "                        'flow_duration': 0,\n",
    "                        'elephant': 0,\n",
    "                    }\n",
    "\n",
    "        \n",
    "        if index % 100000 == 0:\n",
    "            print(f'{index} rows processed')\n",
    "        \n",
    "    # Output csv file\n",
    "    # Convert dictionary to dataframe\n",
    "    data_features = pd.DataFrame.from_dict(flows)\n",
    "\n",
    "    # Transpose the dataframe\n",
    "    data_features = data_features.transpose()\n",
    "    \n",
    "    # Remove index\n",
    "#     data_features = data_features.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d87b822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows processed\n",
      "100000 rows processed\n",
      "200000 rows processed\n",
      "300000 rows processed\n",
      "400000 rows processed\n",
      "500000 rows processed\n",
      "600000 rows processed\n",
      "700000 rows processed\n",
      "800000 rows processed\n",
      "900000 rows processed\n",
      "1000000 rows processed\n",
      "1100000 rows processed\n",
      "1200000 rows processed\n",
      "1300000 rows processed\n",
      "1400000 rows processed\n",
      "1500000 rows processed\n",
      "1600000 rows processed\n",
      "1700000 rows processed\n",
      "1800000 rows processed\n",
      "1900000 rows processed\n",
      "2000000 rows processed\n",
      "2100000 rows processed\n",
      "2200000 rows processed\n",
      "2300000 rows processed\n",
      "2400000 rows processed\n",
      "2500000 rows processed\n",
      "2600000 rows processed\n",
      "2700000 rows processed\n",
      "2800000 rows processed\n",
      "2900000 rows processed\n",
      "3000000 rows processed\n",
      "3100000 rows processed\n",
      "3200000 rows processed\n",
      "3300000 rows processed\n",
      "3400000 rows processed\n",
      "3500000 rows processed\n",
      "3600000 rows processed\n",
      "3700000 rows processed\n",
      "3800000 rows processed\n",
      "3900000 rows processed\n",
      "4000000 rows processed\n",
      "4100000 rows processed\n",
      "4200000 rows processed\n",
      "4300000 rows processed\n",
      "4400000 rows processed\n",
      "4500000 rows processed\n",
      "4600000 rows processed\n",
      "4700000 rows processed\n",
      "4800000 rows processed\n",
      "4900000 rows processed\n",
      "5000000 rows processed\n",
      "5100000 rows processed\n",
      "5200000 rows processed\n",
      "5300000 rows processed\n",
      "5400000 rows processed\n",
      "5500000 rows processed\n",
      "5600000 rows processed\n",
      "5700000 rows processed\n",
      "5800000 rows processed\n",
      "5900000 rows processed\n",
      "6000000 rows processed\n",
      "6100000 rows processed\n",
      "6200000 rows processed\n",
      "6300000 rows processed\n",
      "6400000 rows processed\n",
      "6500000 rows processed\n",
      "6600000 rows processed\n",
      "6700000 rows processed\n",
      "6800000 rows processed\n",
      "6900000 rows processed\n",
      "7000000 rows processed\n",
      "7100000 rows processed\n",
      "7200000 rows processed\n",
      "7300000 rows processed\n",
      "7400000 rows processed\n",
      "7500000 rows processed\n",
      "7600000 rows processed\n",
      "7700000 rows processed\n",
      "7800000 rows processed\n",
      "7900000 rows processed\n",
      "8000000 rows processed\n",
      "8100000 rows processed\n",
      "8200000 rows processed\n",
      "8300000 rows processed\n",
      "8400000 rows processed\n",
      "8500000 rows processed\n",
      "8600000 rows processed\n",
      "8700000 rows processed\n",
      "8800000 rows processed\n",
      "8900000 rows processed\n",
      "9000000 rows processed\n",
      "9100000 rows processed\n",
      "9200000 rows processed\n",
      "9300000 rows processed\n",
      "9400000 rows processed\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "flows = get_flows(packet_trace, 7)\n",
    "\n",
    "# Save dataframe as a csv file without index\n",
    "output_file = 'flows_4.csv'\n",
    "flows.to_csv(output_file, index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345269c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
